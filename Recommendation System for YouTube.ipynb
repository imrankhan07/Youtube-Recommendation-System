{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying with NLP's Lemma names to find the synonyms of the word 'funny' - one mining try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "[['funny_story', 'good_story', 'funny_remark', 'funny'], ['amusing', 'comic', 'comical', 'funny', 'laughable', 'mirthful', 'risible'], ['curious', 'funny', 'odd', 'peculiar', 'queer', 'rum', 'rummy', 'singular'], ['fishy', 'funny', 'shady', 'suspect', 'suspicious'], ['funny']]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "print(\"start\")\n",
    "listnames = []\n",
    "\n",
    "for i,j in enumerate(wn.synsets('funny')):\n",
    "    listnames.append(j.lemma_names())\n",
    "print (listnames) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference based on the above NLP library \n",
    "Since the synonyms seem to be irrelevant in some of the above cases like rummy, singular. So it is fine to manually find few word related to the word 'funny' and mine YouTube based on those search keywords."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining dataset from YouTube\n",
    "\n",
    "First, run the youtubeMiner.py script in your console to get the dataset in comma separated values(CSV) format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Curating dataset by removing redundancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>commentCount</th>\n",
       "      <th>dislikeCount</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>v_id</th>\n",
       "      <th>v_title</th>\n",
       "      <th>viewCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>954</td>\n",
       "      <td>cGKEVtGYr3A</td>\n",
       "      <td>TRY NOT TO LAUGH or GRIN: DeStorm Power Vines ...</td>\n",
       "      <td>140473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>63743</td>\n",
       "      <td>6020</td>\n",
       "      <td>0</td>\n",
       "      <td>363572</td>\n",
       "      <td>aO4dTgt47No</td>\n",
       "      <td>Try Not To Laugh Challenge #4</td>\n",
       "      <td>10085850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>858</td>\n",
       "      <td>1705</td>\n",
       "      <td>0</td>\n",
       "      <td>6999</td>\n",
       "      <td>2B8TjgWgBGg</td>\n",
       "      <td>IMPOSSIBLE NOT TO LAUGH - Funny school fail co...</td>\n",
       "      <td>2315183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>545</td>\n",
       "      <td>1247</td>\n",
       "      <td>0</td>\n",
       "      <td>1341</td>\n",
       "      <td>PQ94T4WAea0</td>\n",
       "      <td>IF YOU LAUGH, YOU LOSE (87% FAIL)</td>\n",
       "      <td>85006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49203</td>\n",
       "      <td>47778</td>\n",
       "      <td>0</td>\n",
       "      <td>163214</td>\n",
       "      <td>_i4qBHd0FJo</td>\n",
       "      <td>*I BET  MY KIDNEY YOU WILL LAUGH**</td>\n",
       "      <td>12079480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 commentCount dislikeCount favoriteCount likeCount         v_id  \\\n",
       "0         0.0           87          155             0       954  cGKEVtGYr3A   \n",
       "1         1.0        63743         6020             0    363572  aO4dTgt47No   \n",
       "2         2.0          858         1705             0      6999  2B8TjgWgBGg   \n",
       "3         3.0          545         1247             0      1341  PQ94T4WAea0   \n",
       "4         4.0        49203        47778             0    163214  _i4qBHd0FJo   \n",
       "\n",
       "                                             v_title viewCount  \n",
       "0  TRY NOT TO LAUGH or GRIN: DeStorm Power Vines ...    140473  \n",
       "1                      Try Not To Laugh Challenge #4  10085850  \n",
       "2  IMPOSSIBLE NOT TO LAUGH - Funny school fail co...   2315183  \n",
       "3                  IF YOU LAUGH, YOU LOSE (87% FAIL)     85006  \n",
       "4                 *I BET  MY KIDNEY YOU WILL LAUGH**  12079480  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv('YTlaughable123.csv', encoding='utf-8')\n",
    "\n",
    "df1 = df.drop_duplicates(['v_title'])\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1230, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "### Why not a recommendation based on the number of views and likes ? \n",
    "\n",
    "I have collected the videos along with their view count, number of likes and dislikes in the csv file which mined the YouTube. Based on the above information, it becomes easy to recommend videos based on number of likes and views of the videos just by sorting. But pernolization comes into question with this model of recommendation. So I am planning to introduce some assumptions inorder to make this recommendation system work more personalized.\n",
    "\n",
    "\n",
    "### Assumptions \n",
    "\n",
    "Introducing 6 users in the dataset and whose names are Kathir, Sundhar, Chris, Patrick, MSD and MarkZ in \"Users\". Along with those users, I have also introduced the assumed like count of each video to that paticular user. This may seem to be little fuzzy. But it is like normal mapping of one user to the multiple videos in the dataset and each video will have the like or dislike option in the \"Liked\" column. If the value is 1, then that user liked that video. If the value is 0, then it can be considered as dislike or not watched that video.\n",
    "\n",
    "\n",
    "### Collaborative Filtering\n",
    "\n",
    "In order to implement the recommendation system with personlization, collaborative filtering comes into light. Many companies like MovieLens, Netflix, YouTube etc. are using collaborative filtering in their movies and videos recommendation systems. Collaborative filtering has two different types.\n",
    "1. Model based collaborative filtering \n",
    "2. Memory based collaborative filtering\n",
    "\n",
    "I am using memory based collaborative filtering in this project. Again collaborative filtering has its subtypes. They are item-item filtering and user-user filtering. In particular, I have implemented the recommendation system using item-item filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection based on the above assumption\n",
    "\n",
    "For the following project, I need only around 300 unique videos. But I have sampled around 700 videos with multiple users and their choices.\n",
    "\n",
    "The above mined csv file is changed into users5times100Videos.csv with the mentioned assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphlab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1f74194fec01>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgraphlab\u001b[0m \u001b[1;31m# Need to register for this library but it comes for free to university students\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \"\"\"\n\u001b[0;32m      4\u001b[0m \u001b[0mgraphlab\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'graphlab'"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import graphlab # Need to register for this library but it comes for free to university students \n",
    "\"\"\"\n",
    "graphlab : \n",
    "==========\n",
    "Need to register online for using this library else it will throw an error saying that the product is not registered. \n",
    "\n",
    "Please refer to the following link for further instructions.\n",
    "https://turi.com/download/install-graphlab-create-command-line.html\n",
    "\n",
    "\"\"\"\n",
    "newdf = pd.read_csv('users5times100Videos.csv', encoding='utf-8')\n",
    "from sklearn.utils import shuffle\n",
    "newdf = shuffle(newdf) #Shuffling the dataset in order to randomize the data\n",
    "newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popularity Model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = popularity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = popularity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Preparing data set.</pre>"
      ],
      "text/plain": [
       "Preparing data set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data has 572 observations with 6 users and 99 items.</pre>"
      ],
      "text/plain": [
       "    Data has 572 observations with 6 users and 99 items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data prepared in: 0.004009s</pre>"
      ],
      "text/plain": [
       "    Data prepared in: 0.004009s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>572 observations to process; with 99 unique items.</pre>"
      ],
      "text/plain": [
       "572 observations to process; with 99 unique items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = newdf.ix[:250,:]\n",
    "test = newdf.ix[250:,:]\n",
    "train_data = graphlab.SFrame(train)\n",
    "test_data = graphlab.SFrame(test)\n",
    "popularity_model = graphlab.popularity_recommender.create(train_data, user_id='users', item_id='v_title', target='Liked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------+----------------+------+\n",
      "| users |            v_title            |     score      | rank |\n",
      "+-------+-------------------------------+----------------+------+\n",
      "|  MSD  | Bought Fake Louis Vuitton ... |      1.0       |  1   |\n",
      "|  MSD  |  SLIME PRANK ON BROTHERS CAR! |      1.0       |  2   |\n",
      "|  MSD  | Killer Clown 9 Scare Prank... |      1.0       |  3   |\n",
      "|  MSD  | we got KICKED OUT of our h... |      1.0       |  4   |\n",
      "|  MSD  | MOR FORELSKET I ALBERT! (P... |      1.0       |  5   |\n",
      "|  MSD  | PIZZA DELIVERY PRANK ON MY... |      1.0       |  6   |\n",
      "|  MSD  | Headless man Prank part 2 ... |      1.0       |  7   |\n",
      "|  MSD  | 👑 Tying Peoples Shoes and... |      0.5       |  8   |\n",
      "|  MSD  | GOLD DIGGER PRANK PART 2! ... |      0.5       |  9   |\n",
      "|  MSD  | Old Man Street Workout Pra... |      0.5       |  10  |\n",
      "| MarkZ | Bought Fake Louis Vuitton ... |      1.0       |  1   |\n",
      "| MarkZ |  SLIME PRANK ON BROTHERS CAR! |      1.0       |  2   |\n",
      "| MarkZ | Killer Clown 9 Scare Prank... |      1.0       |  3   |\n",
      "| MarkZ | we got KICKED OUT of our h... |      1.0       |  4   |\n",
      "| MarkZ | MOR FORELSKET I ALBERT! (P... |      1.0       |  5   |\n",
      "| MarkZ | PIZZA DELIVERY PRANK ON MY... |      1.0       |  6   |\n",
      "| MarkZ | Headless man Prank part 2 ... |      1.0       |  7   |\n",
      "| MarkZ | TRY NOT TO LAUGH Funny Ani... | 0.666666666667 |  8   |\n",
      "| MarkZ | Try Not To Laugh or Grin -... | 0.666666666667 |  9   |\n",
      "| MarkZ | TRY NOT TO LAUGH or GRIN: ... | 0.666666666667 |  10  |\n",
      "| Chris | Bought Fake Louis Vuitton ... |      1.0       |  1   |\n",
      "| Chris |  SLIME PRANK ON BROTHERS CAR! |      1.0       |  2   |\n",
      "| Chris | Killer Clown 9 Scare Prank... |      1.0       |  3   |\n",
      "| Chris | we got KICKED OUT of our h... |      1.0       |  4   |\n",
      "| Chris | MOR FORELSKET I ALBERT! (P... |      1.0       |  5   |\n",
      "+-------+-------------------------------+----------------+------+\n",
      "[40 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Get recommendations for first 5 users and print them\n",
    "#users = range(1,6) specifies user ID of first 5 users\n",
    "#k=5 specifies top 5 recommendations to be given\n",
    "user_names = ['Kathir','MSD','MarkZ','Chris','Sundhar','Patrick']\n",
    "popularity_recomm = popularity_model.recommend(users=user_names,k=10)\n",
    "popularity_recomm.print_rows(num_rows=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v_title\n",
       "SLIME PRANK ON BROTHERS CAR!                                                                            1.000000\n",
       "we got KICKED OUT of our home! (PRANK WARS)                                                             1.000000\n",
       "PIZZA DELIVERY PRANK ON MY GIRLFRIEND'S STALKER (GONE WRONG!!!)                                         1.000000\n",
       "Headless man Prank part 2 (slaughter version)- Julien magic                                             1.000000\n",
       "Bought Fake Louis Vuitton Prank/Gold Digger Test!                                                       1.000000\n",
       "MOR FORELSKET I ALBERT! (PRANK)                                                                         1.000000\n",
       "Killer Clown 9 Scare Prank - Shadow Plays                                                               1.000000\n",
       "TRY NOT TO LAUGH or GRIN: DeStorm Power Vines - Funny Vines Compilation 2017 | Life Awesome             0.666667\n",
       "HARDEST VERSION AFV Try Not to Laugh or Grin While Watching Funniest Vines of best funny videos 2017    0.666667\n",
       "TRY NOT TO LAUGH or GRIN: Funny Fails Compilation 2017 - Top 100 Funny Fails Vines Video Ever           0.666667\n",
       "TRY NOT TO LAUGH or GRIN: Funny Animals Vines Compilation 2017 | Funny Animals and Kids Fails Vines     0.666667\n",
       "IMPOSSIBLE NOT TO LAUGH - Funny school fail compilation                                                 0.666667\n",
       "TRY NOT TO LAUGH or GRIN Funny Animals Doing Stupid Things #2 | Funny Animals Vines Compilation 2017    0.666667\n",
       "GIANT WUBBLE BUBBLE CAR PRANK!                                                                          0.666667\n",
       "TRY NOT TO LAUGH or GRIN - Funny Fails Compilation 2017                                                 0.666667\n",
       "TRY NOT TO LAUGH Funny Animals Vines Compilation - Best Funny Videos of Animals Doing Stupid Things     0.666667\n",
       "TRY NOT TO LAUGH (IMPOSSIBLE CHALLENGE) PART 2                                                          0.666667\n",
       "THE BEST PRANK OF ALL TIME!!!                                                                           0.666667\n",
       "TRY NOT TO LAUGH or GRIN: Funny Kids Fails Compilation 2017 | Best Kids Fails Vines of May 2017         0.666667\n",
       "*I BET  MY KIDNEY YOU WILL LAUGH**                                                                      0.666667\n",
       "Name: Liked, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(by='v_title')['Liked'].mean().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collaborative Filtering implemented using graphlab\n",
    "\n",
    "Reminder : Need to register graphlab package inorder to use it but it comes for free\n",
    "\n",
    "I am implementing this recommendation system by making an item-item matrix in which we keep a record of the pair of items which were liked together.\n",
    "\n",
    "In this case, an item is a YouTube video. Once I have the matrix, I use it to determine the best recommendations for a user based on the videos he has already liked. Note that there a few more things to take care in actual implementation which would require deeper mathematical introspection, which I’ll skip for now.\n",
    "\n",
    "Three types of item similarity metrics supported by graphlab are \n",
    "\n",
    "#### 1. Jaccard Similarity: \n",
    "Similarity is based on the number of users which have rated item A and B divided by the number of users who have rated either A or B. It is typically used where we don’t have a numeric rating but just a boolean value like a product being bought or an add being clicked\n",
    "\n",
    "#### 2. Pearson Similarity\n",
    "Similarity is the pearson coefficient between the two vectors\n",
    "\n",
    "#### 3. Cosine Similarity:\n",
    "Similarity is the cosine of the angle between the 2 vectors of the item vectors of A and B. Closer the vectors, smaller will be the angle and larger the cosine\n",
    "\n",
    "For detailed explanation on the cosine similarity and other similar methods, Please check the following links : \n",
    "\n",
    "https://turi.com/products/create/docs/generated/graphlab.recommender.item_similarity_recommender.ItemSimilarityRecommender.html\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Recsys training: model = item_similarity</pre>"
      ],
      "text/plain": [
       "Recsys training: model = item_similarity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Preparing data set.</pre>"
      ],
      "text/plain": [
       "Preparing data set."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data has 251 observations with 3 users and 99 items.</pre>"
      ],
      "text/plain": [
       "    Data has 251 observations with 3 users and 99 items."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>    Data prepared in: 0.007019s</pre>"
      ],
      "text/plain": [
       "    Data prepared in: 0.007019s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Training model from provided data.</pre>"
      ],
      "text/plain": [
       "Training model from provided data."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Gathering per-item and per-user statistics.</pre>"
      ],
      "text/plain": [
       "Gathering per-item and per-user statistics."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Elapsed Time (Item Statistics) | % Complete |</pre>"
      ],
      "text/plain": [
       "| Elapsed Time (Item Statistics) | % Complete |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1.002ms                        | 100        |</pre>"
      ],
      "text/plain": [
       "| 1.002ms                        | 100        |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+--------------------------------+------------+</pre>"
      ],
      "text/plain": [
       "+--------------------------------+------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Setting up lookup tables.</pre>"
      ],
      "text/plain": [
       "Setting up lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Processing data in one pass using dense lookup tables.</pre>"
      ],
      "text/plain": [
       "Processing data in one pass using dense lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| Elapsed Time (Constructing Lookups) | Total % Complete | Items Processed |</pre>"
      ],
      "text/plain": [
       "| Elapsed Time (Constructing Lookups) | Total % Complete | Items Processed |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 1.002ms                             | 43.5             | 43              |</pre>"
      ],
      "text/plain": [
       "| 1.002ms                             | 43.5             | 43              |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>| 2.004ms                             | 100              | 99              |</pre>"
      ],
      "text/plain": [
       "| 2.004ms                             | 100              | 99              |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>+-------------------------------------+------------------+-----------------+</pre>"
      ],
      "text/plain": [
       "+-------------------------------------+------------------+-----------------+"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finalizing lookup tables.</pre>"
      ],
      "text/plain": [
       "Finalizing lookup tables."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Generating candidate set for working with new users.</pre>"
      ],
      "text/plain": [
       "Generating candidate set for working with new users."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished training in 0.003007s</pre>"
      ],
      "text/plain": [
       "Finished training in 0.003007s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------------------+----------------+------+\n",
      "| users |            v_title            |     score      | rank |\n",
      "+-------+-------------------------------+----------------+------+\n",
      "|  MSD  | 👑 Tying Peoples Shoes and... | 0.280174380203 |  1   |\n",
      "|  MSD  | GOLD DIGGER PRANK PART 2! ... | 0.280174380203 |  2   |\n",
      "|  MSD  | Old Man Street Workout Pra... | 0.280174380203 |  3   |\n",
      "|  MSD  |      Bait Backpack Prank      | 0.280174380203 |  4   |\n",
      "|  MSD  | WE GOT JAKE PAUL ARRESTED!... | 0.280174380203 |  5   |\n",
      "|  MSD  | CRAZY SNAKE PRANK ON GIRLF... | 0.280174380203 |  6   |\n",
      "|  MSD  | GOLD DIGGER PRANK PART 3! ... | 0.280174380203 |  7   |\n",
      "|  MSD  | Naga Chaitanya Prank call ... | 0.280174380203 |  8   |\n",
      "|  MSD  | CAUGHT CHEATING on my Girl... | 0.280174380203 |  9   |\n",
      "|  MSD  |            v_title            | 0.280174380203 |  10  |\n",
      "| MarkZ | TRY NOT TO LAUGH Funny Ani... | 0.332663271427 |  1   |\n",
      "| MarkZ | Try Not To Laugh or Grin -... | 0.332663271427 |  2   |\n",
      "| MarkZ | TRY NOT TO LAUGH or GRIN: ... | 0.332663271427 |  3   |\n",
      "| MarkZ | Try Not To Laugh Watching ... | 0.332663271427 |  4   |\n",
      "| MarkZ | TRY NOT TO LAUGH or GRIN: ... | 0.332663271427 |  5   |\n",
      "| MarkZ | TRY NOT TO LAUGH or GRIN: ... | 0.332663271427 |  6   |\n",
      "| MarkZ | *I BET  MY KIDNEY YOU WILL... | 0.332663271427 |  7   |\n",
      "| MarkZ | IMPOSSIBLE NOT TO LAUGH - ... | 0.332663271427 |  8   |\n",
      "| MarkZ | Try Not To Laugh Challenge #4 | 0.332663271427 |  9   |\n",
      "| MarkZ | TRY NOT TO LAUGH or GRIN: ... | 0.332663271427 |  10  |\n",
      "| Chris | TRY NOT TO LAUGH Funny Ani... | 0.332663271427 |  1   |\n",
      "| Chris | Try Not To Laugh or Grin -... | 0.332663271427 |  2   |\n",
      "| Chris | TRY NOT TO LAUGH or GRIN: ... | 0.332663271427 |  3   |\n",
      "| Chris | Try Not To Laugh Watching ... | 0.332663271427 |  4   |\n",
      "| Chris | TRY NOT TO LAUGH or GRIN: ... | 0.332663271427 |  5   |\n",
      "+-------+-------------------------------+----------------+------+\n",
      "[40 rows x 4 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Train Model\n",
    "item_sim_model = graphlab.item_similarity_recommender.create(train_data, user_id='users', item_id='v_title', target='Liked', similarity_type='cosine')\n",
    "\n",
    "#Make Recommendations:\n",
    "item_sim_recomm = item_sim_model.recommend(users=user_names,k=10)\n",
    "item_sim_recomm.print_rows(num_rows=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics for this Recommendation System \n",
    "\n",
    "#### 1. Recall\n",
    "What ratio of items that a user likes were actually recommended.\n",
    "If a user likes say 5 items and the recommendation decided to show 3 of them, then the recall is 0.6\n",
    "\n",
    "#### 2. Precision\n",
    "Out of all the recommended items, how many the user actually liked?\n",
    "If 5 items were recommended to the user out of which he liked say 4 of them, then precision is 0.8\n",
    "\n",
    "For further information for Recall and Precision, Please refer the following link : \n",
    "https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Evaluate model M0\n",
      "\n",
      "Precision and recall summary statistics by cutoff\n",
      "+--------+----------------+-----------------+\n",
      "| cutoff | mean_precision |   mean_recall   |\n",
      "+--------+----------------+-----------------+\n",
      "|   1    |      1.0       | 0.0193566882871 |\n",
      "|   2    |      1.0       | 0.0387133765743 |\n",
      "|   3    |      1.0       | 0.0580700648614 |\n",
      "|   4    |      1.0       | 0.0774267531486 |\n",
      "|   5    |      1.0       | 0.0967834414357 |\n",
      "|   6    |      1.0       |  0.116140129723 |\n",
      "|   7    |      1.0       |  0.13549681801  |\n",
      "|   8    |      1.0       |  0.154853506297 |\n",
      "|   9    |      1.0       |  0.174210194584 |\n",
      "|   10   |      1.0       |  0.193566882871 |\n",
      "+--------+----------------+-----------------+\n",
      "[10 rows x 3 columns]\n",
      "\n",
      "PROGRESS: Evaluate model M1\n",
      "\n",
      "Precision and recall summary statistics by cutoff\n",
      "+--------+----------------+-----------------+\n",
      "| cutoff | mean_precision |   mean_recall   |\n",
      "+--------+----------------+-----------------+\n",
      "|   1    |      1.0       | 0.0193566882871 |\n",
      "|   2    |      1.0       | 0.0387133765743 |\n",
      "|   3    |      1.0       | 0.0580700648614 |\n",
      "|   4    |      1.0       | 0.0774267531486 |\n",
      "|   5    |      1.0       | 0.0967834414357 |\n",
      "|   6    |      1.0       |  0.116140129723 |\n",
      "|   7    |      1.0       |  0.13549681801  |\n",
      "|   8    |      1.0       |  0.154853506297 |\n",
      "|   9    |      1.0       |  0.174210194584 |\n",
      "|   10   |      1.0       |  0.193566882871 |\n",
      "+--------+----------------+-----------------+\n",
      "[10 rows x 3 columns]\n",
      "\n",
      "Model compare metric: precision_recall\n",
      "Canvas is accessible via web browser at the URL: http://localhost:61461/index.html\n",
      "Opening Canvas in default web browser.\n"
     ]
    }
   ],
   "source": [
    "model_performance = graphlab.compare(test_data, [popularity_model, item_sim_model])\n",
    "graphlab.show_comparison(model_performance,[popularity_model, item_sim_model])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
